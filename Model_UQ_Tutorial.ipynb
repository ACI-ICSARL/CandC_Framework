{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a25a1841-560c-4be5-9184-0c1ec27729b7",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to provide a walkthrough of the intended use of the CandC framework for uncertainty quantification and out-of-distribution detection.\n",
    "\n",
    "We will use a  and examine their performance on MNIST and EMNIST data.\n",
    "\n",
    "From there we will walk through how to use the model_uq interface.\n",
    "\n",
    "Specifically we will explore the following:\n",
    "1. the Certainty and Competence features of the CandC framework;\n",
    "2. the certainty score distribution methods;\n",
    "3. the model uq interface, and separately, the following data objects:\n",
    "    i. asssignment_df\n",
    "   ii. certainties\n",
    "  iii. certainty distribution\n",
    "   iv. model data\n",
    "    v. omicron data\n",
    "   vi. scores\n",
    "4. the out-of-distribution tests for the deterministic MNIST models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "336592e7-90ad-4e79-9503-9490f922da24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "from torchvision.datasets import MNIST, EMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50\n",
    "import CandC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c01b3-35c9-4901-a2a1-722727a13ad5",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2541d97-e088-439f-86e1-3f90fb210d72",
   "metadata": {},
   "source": [
    "Unfortunately, torch is not perfect and we cannot directly download the EMNIST data. We recommend downloading the binaries directly from the EMNIST website with the `Binary format as the original MNIST dataset` selected (https://www.nist.gov/itl/products-and-services/emnist-dataset), (https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip) or from the following link (https://marvinschmitt.com/blog/emnist-manual-loading/) (use wget -p ./data/EMNIST 'address'> or  curl -p ./data/EMNIST 'address').\n",
    "\n",
    "Finally run:\n",
    "`for file in *.gz; do\n",
    "  gunzip -c \"$file\" > /path/to/destination/\"${file%.gz}\"\n",
    "done`\n",
    "\n",
    "If errors occur, make sure the unzipped files are inside ./data/EMNIST/raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae29d1e3-8720-4284-8706-8e7f1de005b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (e.g., normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet50 requires 224x224 input size\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# Load MNIST dataset (digits)\n",
    "train_mnist_data = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_mnist_loader = DataLoader(train_mnist_data, batch_size=64, shuffle=True)\n",
    "test_mnist_data = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_mnist_loader = DataLoader(test_mnist_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Load EMNIST dataset (letters)\n",
    "# Ensure 'split' is set to 'letters' for alphabet characters\n",
    "\n",
    "emnist_data = EMNIST(root=os.path.join(os.getcwd(),'data'), \n",
    "                     split='letters',\n",
    "                     train=False,\n",
    "                     download=False, \n",
    "                     transform=transform)\n",
    "emnist_loader = DataLoader(emnist_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "223bdad6-0c6d-48b0-a6aa-f38284eba7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset EMNIST\n",
       "    Number of datapoints: 20800\n",
       "    Root location: /home/jovyan/CandC_Framework/data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               Grayscale(num_output_channels=1)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emnist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79bae794-5e88-4549-b656-f24b1253f765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = resnet50(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Modify the final fully connected layer to output 10 classes (for MNIST digits 0-9)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb362801-0de4-4db1-ac1c-89d8ce29058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb836dce-5d24-46ec-86d4-8d74aa1e2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss and accuracy\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_accuracy = correct / total\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49915ad-9909-4365-972d-3e91f60c9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Accumulate loss and accuracy\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss = running_loss / total\n",
    "    test_accuracy = correct / total\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b0645-a585-41d4-b14c-0392c1713704",
   "metadata": {},
   "source": [
    "## Train and test model on the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0929de44-0ff4-4085-b842-911f84edadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "if not 'mnist_ex.pt' in os.listdir(os.path.join(os.getcwd(),'tutorial')):\n",
    "    train_model(model, train_mnist_loader, criterion, optimizer, num_epochs=5, device=device)\n",
    "else:\n",
    "    model = torch.load(os.path.join(os.getcwd(),'tutorial','mnist_ex.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0343295f-38a8-4464-9128-293c6252849c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0281, Test Accuracy: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.028100473149446772, 0.9905)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "test_model(model, test_mnist_loader, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f98424-0aa7-4cc8-9751-e0f194c8df47",
   "metadata": {},
   "source": [
    "## Set up model uq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d2fe0-b153-4374-a7ff-361da9229b07",
   "metadata": {},
   "source": [
    "Now that we have our in-distribution and out-of-distribution test samples, let's run through the model uq interface.\n",
    "\n",
    "First, let's set up the model uq environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9845275-cccf-4176-95a0-55e6231038d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uq_params = dict({ 'name': 'mnist_example',\n",
    "                        'device': device,\n",
    "                        'model': model,\n",
    "                        'data_address': os.path.join(os.getcwd(),'data'),\n",
    "                        'model_uq_address': os.path.join(os.getcwd(),'example_model_uq'),\n",
    "                        'tpr_threshold': 0.95,\n",
    "                        'n_class' : 10, # This is because the MNIST dataset is our baseline, and this consists of the 10 digits\n",
    "                       })\n",
    "\n",
    "model_uq = CandC.model_uq.Model_UQ(**model_uq_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9652f7-d411-47e9-bb48-3302fece9156",
   "metadata": {},
   "source": [
    "Now, importantly, omitted the model_address key-value in the model_uq_params. Since we want to access the model we have just trained, let's go ahead and save this model so that we may be able to load it in as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65592b5d-e3f8-4004-a522-b3c4ea768eb5",
   "metadata": {},
   "source": [
    "Further, even though we omitted the model_address, the model_uq default creates on for us. Let's use that.\n",
    "\n",
    "The default can be found at os.path.join(os.getcwd(),'model_address'). Let's update this as follows to save in the tutorial folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e59d0b8-8614-433e-b077-acaefd27a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uq.model_address = os.path.join(os.getcwd(),'tutorial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc737d6-4939-4add-bae6-4582d8dd5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=model,f=os.path.join(os.getcwd(),'tutorial','mnist_ex.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a335c5-4121-4850-9e2e-a49a5a483ae8",
   "metadata": {},
   "source": [
    "### Formatting the Input_Data and Output_Data\n",
    "\n",
    "The Input_class has the following possible attributes:\n",
    "\n",
    "1. 'name'\n",
    "2. 'input_data_features'\n",
    "3. 'input_dataloader'\n",
    "4. 'classification_categories'\n",
    "5. 'labeled_data'\n",
    "6. 'input_data_labeled'\n",
    "7. 'classification_scheme'\n",
    "8. 'safevalues'\n",
    "\n",
    " \n",
    "There are several ways to encode input_data and output_data for the Model_UQ object. The first decision one has to make is whether the input data is stored with a dataloader or with features and labels separately loaded as np.array or torch.Tensor objects.\n",
    "\n",
    "Since we have used dataloaders, we'll go ahead and load in the objects with the dataloader as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f02c072b-ec59-4b15-96a6-ef75db43fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_categories=dict({\n",
    "    0:0,\n",
    "    1:1,\n",
    "    2:2,\n",
    "    3:3,\n",
    "    4:4,\n",
    "    5:5,\n",
    "    6:6,\n",
    "    7:7,\n",
    "    8:8,\n",
    "    9:9})\n",
    "input_data=dict({\n",
    "    'name': 'mnist_example',\n",
    "    'input_dataloader':test_mnist_loader,\n",
    "    'classification_categories': classification_categories,\n",
    "    'labeled_data':True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a885ac-605e-4523-85c8-c736a2986a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing with provided data and model.\n",
      "Filling in data labels from dataloader.\n"
     ]
    }
   ],
   "source": [
    "model_data= CandC.model_uq.data.Model_Data(model=model,data=input_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdbdc59-fe4c-40a1-b03f-d94759c23906",
   "metadata": {},
   "source": [
    "We have loaded in the model_data. This took the input data ditionary and the model we have trained, and produced an object which also contains our output data. Further, this data is softmax adjusted by default. The full suite of attributes generated is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b17102e-dfbf-4611-b404-c554e9501e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'input_dataloader', 'classification_categories', 'labeled_data', 'input_data_labeled', 'output', 'prediction'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.to_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b71cfb51-2281-4036-a061-f33b507b875c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4089e-12, 2.7384e-08, 9.7237e-08,  ..., 1.0000e+00, 3.5737e-14,\n",
       "         1.9997e-07],\n",
       "        [8.3562e-09, 3.5649e-09, 1.0000e+00,  ..., 1.6583e-09, 7.1121e-09,\n",
       "         1.6743e-08],\n",
       "        [1.3383e-08, 9.9996e-01, 3.3536e-05,  ..., 2.9982e-07, 3.9025e-07,\n",
       "         1.0370e-08],\n",
       "        ...,\n",
       "        [8.4576e-11, 1.4826e-08, 3.5245e-08,  ..., 3.5793e-08, 2.5801e-07,\n",
       "         1.3964e-07],\n",
       "        [2.4115e-09, 1.2591e-09, 1.9071e-09,  ..., 1.0270e-08, 1.2999e-06,\n",
       "         6.9387e-07],\n",
       "        [1.5548e-07, 8.2569e-10, 1.4350e-06,  ..., 1.3982e-14, 3.2639e-06,\n",
       "         3.7087e-07]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ff273e5-b495-4159-b2ea-4bde121d6ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1,  ..., 4, 5, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f9bc500-03e7-43af-a29e-52908efb910a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd89f149-8b08-4fcd-b1b3-2da7e1d56575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1,  ..., 4, 5, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.input_data_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4c4af-d038-4a5c-9a44-3705d464416d",
   "metadata": {},
   "source": [
    "Let's save this object in the data folder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23e0cadb-5013-4998-a7de-c691f9b5e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.save(address=os.path.join(os.getcwd(),'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3db321dc-8489-4362-99bb-30832438291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model_data object attributes.\n"
     ]
    }
   ],
   "source": [
    "model_data = CandC.model_uq.data.Model_Data(model_data_address=os.path.join(os.getcwd(),'data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc90064e-2c28-410a-a719-1f4f2c1c7b5f",
   "metadata": {},
   "source": [
    "Now that we've explored the model_data, let's generate the model uq interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cab4ebe0-2f0e-4d0b-917d-7c4300129036",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uq_params = dict({\n",
    "    'name': 'mnist_example',\n",
    "    'device': device,\n",
    "    'model' : model,\n",
    "    'model_address': os.path.join(os.getcwd(),'tutorial','ex_mnist.pt'),\n",
    "    'data_address': os.path.join(os.getcwd(),'data'),\n",
    "    'model_uq_address':os.path.join(os.getcwd(),'tutorial','model_uq'),\n",
    "    'tpr_threshold':0.95,\n",
    "    'n_class':10, # This technically should correspond to the number of keys in the classification_cat we use for the corresponding model_data we use as our baseline for statistics\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "751aca9a-06c7-48d9-b26b-f7ec4946df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uq = CandC.model_uq.Model_UQ(**model_uq_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba93c742-6eb3-48a3-915e-11d86f9a45e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment DF saved at /home/jovyan/CandC_Framework/data\n",
      "Loading model_data object attributes.\n",
      "Now gathering certainties\n",
      "Original certainty shape is torch.Size([10000, 10, 10]) from predictions shape torch.Size([10000, 10])\n",
      "Finished gathering certainties.\n",
      "The length of classification_cat is 10000\n",
      " the length of predictions is 10000\n",
      " the length of certainty scores is 10000\n",
      "Generating scores object\n",
      "Attempting to load assignment_df saved at /home/jovyan/CandC_Framework/data\n",
      "Loading model_data object attributes.\n",
      "Gathering APS\n",
      "Gathering RAS\n",
      "Gathering CK\n",
      "Gathering PE\n",
      "Gathering MIP\n",
      "Gathering CC\n",
      "Gathering EC\n",
      "The length of classification_cat is 10000\n",
      " the length of predictions is 10000\n",
      " the length of certainty scores is 10000\n",
      "Attempting to load assignment_df saved at /home/jovyan/CandC_Framework/data\n",
      "Gathering Certainty Score stats\n",
      "\t -Gathering in sample certainty scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:02<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t -Gathering MWU Results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The omicron gatherlist has 10 many categories\n",
      "Gathering the omicrons for all observed labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering omicron data: 100%|██████████| 10/10 [00:00<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input', 'distribution_status', 'tpr_threshold', 'logistic_params'])\n",
      "There are 10000 total items.\n",
      " There are 9905 in-distribution items.\n",
      " There are 95 out-of-distribution/FP items\n",
      "The accuracy of the log omicron model after fitting is 0.9907\n",
      "Model saved at /home/jovyan/CandC_Framework/tutorial/model_uq\n"
     ]
    }
   ],
   "source": [
    "alloutputs = model_uq.fill_uq(model_data=model_data,\n",
    "                              certainty_dist_name= \"mnist_example_certainty_dist\",\n",
    "                              return_assignment_df=True,\n",
    "                              return_model_data=True,\n",
    "                              return_certainties=True,\n",
    "                              return_certainty_dist =True,\n",
    "                              return_scores = True,\n",
    "                              return_omicrons=True,\n",
    "                             verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0bf999-91ff-4846-b8ae-a63825c468b4",
   "metadata": {},
   "source": [
    "Now that we have filled in the initial uncertainty quantification information, we can explore the outputs that we have loaded into memory with the alloutputs object. \n",
    "\n",
    "By default no outputs are made, but we can specify that when applying the fill_uq methods that we can return any of the following as part of a key-value pair in a dictionary:\n",
    "1. model_data\n",
    "2. assignment_df\n",
    "3. certainties\n",
    "4. certainty distribution\n",
    "5. scores\n",
    "6. omicrons\n",
    "\n",
    "In particular, we might want to see what the scores for our model are in order to gauge it's quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9aed74-198d-4513-9a07-d73fdbdc48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = alloutputs['scores'].scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba2e13-8ac9-4458-8ff1-2561de6d708a",
   "metadata": {},
   "source": [
    "In order to simplify our work, we've just extracted the saved scores dictionary that is an attribute of the Scores object stored in the alloutputs object returned by the model_uq.fill_uq method.\n",
    "\n",
    "Let's now examine the scores of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96de4776-2667-45c6-938b-c464f376539b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MCA': 0.9905,\n",
       " 'TP': 9905,\n",
       " 'FP': 95,\n",
       " 'F1': array([0.9959142 , 0.99296394, 0.98800959, 0.993083  , 0.98680203,\n",
       "        0.99159664, 0.99112272, 0.98321816, 0.99282051, 0.98956781]),\n",
       " 'APS': 0.9905537373639556,\n",
       " 'RAS': 0.9999566569432103,\n",
       " 'CK': 0.9894403117344469,\n",
       " 'PE': None,\n",
       " 'MIP': None,\n",
       " 'CC': array(0.8860517, dtype=float32),\n",
       " 'EC': 0.9742994140625}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc08ac-916b-43e6-be41-b0d832a7d75b",
   "metadata": {},
   "source": [
    "We observe the following:\n",
    "\n",
    "Accuracy is .9905\n",
    "\n",
    "There are 9905 TP\n",
    "\n",
    "There are 95 FP\n",
    "\n",
    "The F1 scores within each category are superlative: \n",
    "\\n [0.9959142 , 0.99296394, 0.98800959, 0.993083  , 0.98680203,\n",
    "        0.99159664, 0.99112272, 0.98321816, 0.99282051, 0.98956781],\n",
    "        \n",
    "The average precision score 'APS' is 0.9905537373639556,\n",
    "\n",
    "The average AUROC score ('RAS') is 0.9999566569432103\n",
    "\n",
    "Cohen's Kappa 'CK' is 0.9894403117344469\n",
    "\n",
    "The component competence  'CC' is 0.8861,\n",
    "\n",
    "whereas the empirical 'EC' is 0.9742994140625\n",
    "\n",
    "\n",
    "Since there are 10 categories, we conclude that the model is Expert, but not prescient, as the empirical competence is above the component competence.\n",
    "\n",
    "Now, let's dig in a little further to see the MWU test scores relative to the TP and FP for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcbfc654-c951-4b75-8bd2-db7e724fbd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_competencies=alloutputs['scores'].empirical_competencies\n",
    "in_sample_cert_scores = alloutputs['scores'].in_sample_cert_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87e34219-9903-479c-8118-726a7543c860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9877104651952326,\n",
       " 1: 0.9751871458996378,\n",
       " 2: 0.9625806962436194,\n",
       " 3: 0.9835620406111316,\n",
       " 4: 0.9652657450934653,\n",
       " 5: 0.9836474308641867,\n",
       " 6: 0.9834291145221068,\n",
       " 7: 0.9611088020768098,\n",
       " 8: 0.9831020167616548,\n",
       " 9: 0.9595922948829682}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empirical_competencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34a3b0ca-3104-4bed-898b-186fc19202e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 Global scores': MannwhitneyuResult(statistic=array([6753.]), pvalue=array([2.63747956e-05])),\n",
       " '2 Global scores': MannwhitneyuResult(statistic=array([2044.]), pvalue=array([0.0159561])),\n",
       " '3 Global scores': MannwhitneyuResult(statistic=array([5016.]), pvalue=array([0.00010729])),\n",
       " '4 Global scores': MannwhitneyuResult(statistic=array([9622.]), pvalue=array([6.83349024e-08])),\n",
       " '5 Global scores': MannwhitneyuResult(statistic=array([6079.]), pvalue=array([1.13116159e-05])),\n",
       " '6 Global scores': MannwhitneyuResult(statistic=array([8499.]), pvalue=array([2.27317547e-07])),\n",
       " '7 Global scores': MannwhitneyuResult(statistic=array([30893.]), pvalue=array([1.46844476e-19])),\n",
       " '8 Global scores': MannwhitneyuResult(statistic=array([5786.]), pvalue=array([2.49008035e-05])),\n",
       " '9 Global scores': MannwhitneyuResult(statistic=array([12405.]), pvalue=array([1.33959478e-08]))}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_cert_scores['MWU Results']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb26b410-a2df-4d3a-a81f-8fcb1a463352",
   "metadata": {},
   "source": [
    "First, we see that category by category, we have extremely high empirical competence scores. It is worth pointing out that there are two contributors to this high empirical competence score, the first is that certainty scores are extremely high in most cases, and FP occur extremely infrequently. Relying solely on the certainty score on a one-off basis is not the best guarantee of detection for a FP. \n",
    "\n",
    "When looking at the distribution of certainty scores for TP and FPs within each category, we find the MWU statistic and associated in p-values for all categories are sufficiently high and low respectively that we may reject the null-hypothesis that TP and FP are drawn from the same distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7e38e8-3fd4-4166-871f-20ff86385c96",
   "metadata": {},
   "source": [
    "#### Deeper Dive Into FP Certainties\n",
    "\n",
    "At this point we have several objects that we can examine to get a better sense of how the model fails.\n",
    "\n",
    "We will first look into the category which has the most FPs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0594367-e025-4918-a24a-6e93e884efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_df=alloutputs['assignment_df'].data\n",
    "assignment_df_fp = assignment_df.loc[assignment_df.predictive_status=='FP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d22a1aa-1c2a-4828-9188-38c0e6bf5cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "2    23\n",
       "4    16\n",
       "1    10\n",
       "3     9\n",
       "5     8\n",
       "8     8\n",
       "9     8\n",
       "6     8\n",
       "0     3\n",
       "7     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment_df_fp.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a7144-73b3-49f3-b287-04a301236214",
   "metadata": {},
   "source": [
    "We see that the '2' digit has the most FPs (23). Let's now examine the certainties for the 2 category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aff7491c-f866-466b-b676-9797a0c3e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_2_indices = assignment_df.loc[(assignment_df.prediction==2) & (assignment_df.predictive_status=='TP')].index.to_list()\n",
    "fp_2_indices=assignment_df_fp.loc[assignment_df_fp.prediction==2].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2e9fe65-92de-4e6c-97a6-3d6843cbda37",
   "metadata": {},
   "outputs": [],
   "source": [
    "certainties = alloutputs['certainties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44b12fc2-2b72-44f4-a0b8-6a8c1043d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_2_output = certainties.output[tp_2_indices]\n",
    "tp_2_certainties = certainties.certainty[tp_2_indices]\n",
    "fp_2_output = certainties.output[fp_2_indices]\n",
    "fp_2_certainties = certainties.certainty[fp_2_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13683e8b-2a38-4ab2-b1bc-43a407c95a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.3562e-09, 3.5649e-09, 1.0000e+00, 1.3180e-08, 8.3749e-10, 1.1831e-09,\n",
       "        2.5862e-09, 1.6583e-09, 7.1121e-09, 1.6743e-08])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_2_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0475624a-849d-468b-aa51-6a058e4177cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.1300e-07, 2.0458e-04, 8.4215e-01, 1.0680e-06, 1.5226e-01, 1.8312e-05,\n",
       "        5.2740e-03, 1.5429e-06, 8.5194e-05, 1.2366e-06])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_2_output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63215a-0f94-4e1b-8837-9d24673f7d30",
   "metadata": {},
   "source": [
    "We observe that the first TP example provides an effective absolute confidence that the input is a '2', whereas the first FP example, although strongly predicting the input is a 2 (conditioned on the input features, the softmax adjusted probability is that .84215 that this input should be a 2), we nonetheless see at least one other alternative that has roughly the same order of magnitude, the '4' digit.\n",
    "\n",
    "We can expand this analysis out further, using the flattened certainties.  Since these are reduced from a 10x10 matrices to a vector of length 45, let's check the first tp_2 certainty and the first fp_2 certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0746554c-31df-4a47-b8fe-415a74b3e22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.7913e-09, -1.0000e+00, -4.8236e-09,  7.5188e-09,  7.1731e-09,\n",
       "         5.7701e-09,  6.6979e-09,  1.2442e-09, -8.3871e-09, -1.0000e+00,\n",
       "        -9.6150e-09,  2.7274e-09,  2.3818e-09,  9.7873e-10,  1.9066e-09,\n",
       "        -3.5472e-09, -1.3178e-08,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "         1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.2342e-08,\n",
       "         1.1997e-08,  1.0594e-08,  1.1522e-08,  6.0678e-09, -3.5635e-09,\n",
       "        -3.4561e-10, -1.7487e-09, -8.2084e-10, -6.2746e-09, -1.5906e-08,\n",
       "        -1.4031e-09, -4.7523e-10, -5.9290e-09, -1.5560e-08,  9.2785e-10,\n",
       "        -4.5259e-09, -1.4157e-08, -5.4538e-09, -1.5085e-08, -9.6312e-09])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_2_certainties[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65a12b5a-cc7f-4786-97fa-f9e875669415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0416e-04, -8.4215e-01, -6.5502e-07, -1.5226e-01, -1.7899e-05,\n",
       "        -5.2736e-03, -1.1299e-06, -8.4781e-05, -8.2363e-07, -8.4195e-01,\n",
       "         2.0351e-04, -1.5206e-01,  1.8627e-04, -5.0694e-03,  2.0303e-04,\n",
       "         1.1938e-04,  2.0334e-04,  8.4215e-01,  6.8989e-01,  8.4213e-01,\n",
       "         8.3688e-01,  8.4215e-01,  8.4207e-01,  8.4215e-01, -1.5226e-01,\n",
       "        -1.7244e-05, -5.2729e-03, -4.7484e-07, -8.4126e-05, -1.6860e-07,\n",
       "         1.5224e-01,  1.4699e-01,  1.5226e-01,  1.5218e-01,  1.5226e-01,\n",
       "        -5.2557e-03,  1.6769e-05, -6.6882e-05,  1.7075e-05,  5.2724e-03,\n",
       "         5.1888e-03,  5.2727e-03, -8.3651e-05,  3.0623e-07,  8.3958e-05])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_2_certainties[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0b98c-dc80-4a0a-8fa3-b155a780f20a",
   "metadata": {},
   "source": [
    "We get some sense immediately that the true positive has more entries whose absolute value is near 1, indicating near absolute certainty of the given prediction, whereas the FP certainty has no clear indication of that being the case. \n",
    "\n",
    "Setting up our motivation for the omicron score, let's do a quick comparison between the first pair of TP certainties, FP certainties and pair of TP against FP certainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7a6c2a8-b2a2-4b5a-9580-e1f48ec20766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The norm of the 0 and 1 TP is 5.3419153545064546e-08\n",
      "The norm of the 0 and 1 FP is 0.9168991446495056\n",
      "The norm of the 0 TP against the 0 FP is 0.6937397718429565\n",
      "The norm of the 1 and 2 TP is 0.0004051334981340915\n",
      "The norm of the 1 and 2 FP is 0.36251553893089294\n",
      "The norm of the 1 TP against the 1 FP is 1.0553745031356812\n",
      "The norm of the 2 and 3 TP is 0.00932549312710762\n",
      "The norm of the 2 and 3 FP is 0.7669994235038757\n",
      "The norm of the 2 TP against the 2 FP is 1.4160065650939941\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"The norm of the {} and {} TP is {}\".format(i,i+1, torch.norm(tp_2_certainties[i]-tp_2_certainties[i+1])))\n",
    "    print(\"The norm of the {} and {} FP is {}\".format(i,i+1, torch.norm(fp_2_certainties[i]-fp_2_certainties[i+1])))\n",
    "    print(\"The norm of the {} TP against the {} FP is {}\".format(i,i, torch.norm(tp_2_certainties[i]-fp_2_certainties[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce8158-6bfd-4008-a1f9-71ad1685d821",
   "metadata": {},
   "source": [
    "From a relatively small sample, we see that the certainties of the pairs of TPs are relatively close to one another in a large dimensional space, whereas the FP pairs are are several of magnitudes farther apart than their TP counterparts. \n",
    "\n",
    "Finally, the pairs of TP and FP certainties are similarly spaced farther apart than the TP pairs, and several of the FP pairs.\n",
    "\n",
    "We may start to anticipate that 'average' distance between the two predictive statuses should be detectable. Further, by the central limit theorem, the 'averages' of these norms ought to be normally distributed, so that one can distinguish distributions of high-dimensional data with respect to a univariate distribution. This is, in effect, the entire motivation for the calculation and application of the omicron statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b49f4c1-3871-4bf7-a5e6-8eace3cd2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "omicrons = alloutputs['omicrons'].omicrons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881419fc-c4f6-4c10-ab80-01e1a93ea3eb",
   "metadata": {},
   "source": [
    "Now that we've loaded in the omicrons, let's compute the distance between the two subsamples of  the certainties for the TP and FP examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa7c17e0-5aa8-4a3f-9991-deb35277fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_fp_2_omicrons = CandC.oodd.omicrons.omicron_fn(omicrons[2]['TP']['certainty_sample'],omicrons[2]['FP']['certainty_sample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16da9cb6-67c0-4d02-9ce9-aa3ce44ab1d7",
   "metadata": {},
   "source": [
    "Now let's look at the mean and standard deviation of each respective omicron sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68dd1279-118c-4d1d-8608-2a180cae084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMean\t| Var\n",
      " TP:\t0.03432707488536835\t|\t 0.01810862496495247\t\n",
      " FP:\t 1.1486209630966187\t|\t 0.09058060497045517 \n",
      " TPvFP:\t1.438718557357788 \t|\t0.0001247012405656278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tMean\\t| Var\\n TP:\\t{}\\t|\\t {}\\t\\n FP:\\t {}\\t|\\t {} \\n TPvFP:\\t{} \\t|\\t{}\\n\".format(omicrons[2]['TP']['omicrons'].mean(),\n",
    "                 omicrons[2]['TP']['omicrons'].std()**2,\n",
    "                 omicrons[2]['FP']['omicrons'].mean(),\n",
    "                 omicrons[2]['FP']['omicrons'].std()**2,\n",
    "                 tp_fp_2_omicrons.mean(),\n",
    "                 tp_fp_2_omicrons.std()**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d595de-1eeb-4b20-aee6-79ee06f5c7fd",
   "metadata": {},
   "source": [
    "Examination of the omicron scores for the '2' digit provides the following insights:\n",
    "\n",
    "1. Within the TP predictions, the average distance from the certainties is quite low, although there is significant variance given how close the mean is to 0;\n",
    "2. Within the FP predictions, the average distance from other TP certainties is quite high, indicating both that the model is not consistently replicating the errors that lead to a False Prediction, and does so because it considers multiple distinct alternatives, in contrast to the TP cases where there is little variation in the plausible alternatives; \n",
    "3. The average distance of the TP predictions from the FP predictions is even higher, with an extremely low variance relative to this distance. This lends credibility to the idea that we may use the omicron scores to distinguish a TP from a FP, or an out of distribution example, relative to the use of known in-distribution TPs and an unknown input, indicating that although the observed FPs are far apart from one another, they are further from the TPs, even if predicted to belong to the same label as the TPs.\n",
    "\n",
    "Before proceeding with the out of distribution examples, let's look at the omicrons across all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "159ea6db-06a9-42a7-8cd3-4b06bd513fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tMean\t| Var\n",
      " TP:\t0.03686104342341423\t|\t 0.017980149015784264\t\n",
      " FP:\t 1.0735294818878174\t|\t 0.029328159987926483 \n",
      " TPvFP:\t2.0284767150878906 \t|\t0.0004666907771024853\n",
      "\n",
      "1\tMean\t| Var\n",
      " TP:\t0.05027231201529503\t|\t 0.02661757729947567\t\n",
      " FP:\t 1.021998643875122\t|\t 0.0815143957734108 \n",
      " TPvFP:\t0.9597761034965515 \t|\t0.00021724987891502678\n",
      "\n",
      "2\tMean\t| Var\n",
      " TP:\t0.03432707488536835\t|\t 0.01810862496495247\t\n",
      " FP:\t 1.1486209630966187\t|\t 0.09058060497045517 \n",
      " TPvFP:\t1.438718557357788 \t|\t0.0001247012405656278\n",
      "\n",
      "3\tMean\t| Var\n",
      " TP:\t0.012892150320112705\t|\t 0.005865542218089104\t\n",
      " FP:\t 1.1047720909118652\t|\t 0.06275364756584167 \n",
      " TPvFP:\t0.926129162311554 \t|\t5.230105671216734e-06\n",
      "\n",
      "4\tMean\t| Var\n",
      " TP:\t0.03816358000040054\t|\t 0.015980929136276245\t\n",
      " FP:\t 0.9698021411895752\t|\t 0.09351544082164764 \n",
      " TPvFP:\t0.7662228941917419 \t|\t0.0001458017504774034\n",
      "\n",
      "5\tMean\t| Var\n",
      " TP:\t0.021444860845804214\t|\t 0.007656562607735395\t\n",
      " FP:\t 1.1257102489471436\t|\t 0.021330269053578377 \n",
      " TPvFP:\t1.7247533798217773 \t|\t8.657295984448865e-05\n",
      "\n",
      "6\tMean\t| Var\n",
      " TP:\t0.025651300325989723\t|\t 0.01221117191016674\t\n",
      " FP:\t 1.2159204483032227\t|\t 0.052042629569768906 \n",
      " TPvFP:\t1.7651594877243042 \t|\t6.878795102238655e-05\n",
      "\n",
      "7\tMean\t| Var\n",
      " TP:\t0.15185284614562988\t|\t 0.06361762434244156\t\n",
      " FP:\t 0.4410195052623749\t|\t 0.0 \n",
      " TPvFP:\t1.2012404203414917 \t|\t0.007021849974989891\n",
      "\n",
      "8\tMean\t| Var\n",
      " TP:\t0.019945144653320312\t|\t 0.008510416373610497\t\n",
      " FP:\t 0.9935608506202698\t|\t 0.09900441765785217 \n",
      " TPvFP:\t0.9354613423347473 \t|\t1.3174470950616524e-05\n",
      "\n",
      "9\tMean\t| Var\n",
      " TP:\t0.11307393014431\t|\t 0.056636810302734375\t\n",
      " FP:\t 0.568282425403595\t|\t 0.07318352162837982 \n",
      " TPvFP:\t0.6015380620956421 \t|\t0.0032152202911674976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in sorted(list(omicrons.keys())):\n",
    "    tp_fp_omicrons = CandC.oodd.omicrons.omicron_fn(omicrons[cat]['TP']['certainty_sample'],omicrons[cat]['FP']['certainty_sample'])\n",
    "    print(\"{}\\tMean\\t| Var\\n TP:\\t{}\\t|\\t {}\\t\\n FP:\\t {}\\t|\\t {} \\n TPvFP:\\t{} \\t|\\t{}\\n\".format(cat,\n",
    "                                                                                                  omicrons[cat]['TP']['omicrons'].mean(),\n",
    "                 omicrons[cat]['TP']['omicrons'].std()**2,\n",
    "                 omicrons[cat]['FP']['omicrons'].mean(),\n",
    "                 omicrons[cat]['FP']['omicrons'].std()**2,\n",
    "                 tp_fp_omicrons.mean(),\n",
    "                 tp_fp_omicrons.std()**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4834776a-2362-4824-9c4f-8967db362d3e",
   "metadata": {},
   "source": [
    "Finally, we do not look at omicrons 'globally'. These statistics will be less reliable because the certainties for each predicted category are necessarily concentrated around the values predicted by the category, and so there will be a natural distance betweeen all true positive examples that will necessarily skew the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae7b0d-49e8-42fc-b3a7-b54a9276f828",
   "metadata": {},
   "source": [
    "## Examination of EMNIST data\n",
    "\n",
    "So far we have looked at the model we have trained and its performance on data which we know is a priori drawn from the training and validation distribution. Further, we have seen that this model performs extremely well on the in-distribution data. What we want now are to see how the model performs on data that is a priori out-of-distribution due to belonging to different labels/unknown labels, with features that are sufficiently different from the training features. \n",
    "\n",
    "Specifically, these will be the 'letters' or 'alphabetical' characters in the EMNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26b7ff7b-c97e-4594-97a8-1d0cd1575861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing with provided data and model.\n",
      "Filling in data labels from dataloader.\n"
     ]
    }
   ],
   "source": [
    "emnist_model_data_params=dict({\n",
    "    'name': 'emnist_example',\n",
    "    'input_dataloader':emnist_loader,\n",
    "    'labeled_data':True,\n",
    "})\n",
    "\n",
    "emnist_model_data = CandC.model_uq.data.Model_Data(model=model,data=emnist_model_data_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d51cf7d-5595-4118-a2c9-06d076379d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_model_data.save(address=os.path.join(os.getcwd(),'data'),filename=\"emnist_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a00cc-03b8-4462-8662-b30eb94e1656",
   "metadata": {},
   "source": [
    "With the emnist_model_data saved, we first show how to get the certainties, certainty_score, and predictions independently of a Certainties object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0665aa24-4511-4f0b-a173-36d419289503",
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_certainties,emnist_certainty_scores, emnist_predictions = CandC.candc.get_certainty(emnist_model_data.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fd8c4b2-c3f8-4a79-97bc-e7857e5df208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.histogram(\n",
       "hist=tensor([ 137.,  129.,  136.,  128.,  133.,  133.,  139.,  125.,  106.,  133.,\n",
       "         127.,  126.,  129.,  108.,  129.,  119.,  133.,  101.,  121.,  120.,\n",
       "         111.,  115.,  101.,  112.,  106.,  124.,  108.,  106.,  110.,  129.,\n",
       "         104.,  129.,  117.,  104.,  120.,  125.,  103.,  109.,  117.,  122.,\n",
       "         130.,  117.,  125.,  111.,  107.,  123.,  120.,  138.,  120.,  123.,\n",
       "         108.,  110.,  127.,  100.,  126.,  114.,  140.,  127.,  121.,  103.,\n",
       "         129.,  142.,  119.,  131.,  130.,  119.,  147.,  118.,  134.,  125.,\n",
       "         129.,  130.,  162.,  143.,  165.,  148.,  138.,  147.,  167.,  212.,\n",
       "         173.,  174.,  173.,  170.,  178.,  206.,  232.,  214.,  233.,  246.,\n",
       "         280.,  312.,  330.,  354.,  366.,  420.,  541.,  706., 1060., 4423.]),\n",
       "bin_edges=tensor([2.8133e-05, 1.0028e-02, 2.0028e-02, 3.0027e-02, 4.0027e-02, 5.0027e-02,\n",
       "        6.0026e-02, 7.0026e-02, 8.0026e-02, 9.0026e-02, 1.0003e-01, 1.1003e-01,\n",
       "        1.2002e-01, 1.3002e-01, 1.4002e-01, 1.5002e-01, 1.6002e-01, 1.7002e-01,\n",
       "        1.8002e-01, 1.9002e-01, 2.0002e-01, 2.1002e-01, 2.2002e-01, 2.3002e-01,\n",
       "        2.4002e-01, 2.5002e-01, 2.6002e-01, 2.7002e-01, 2.8002e-01, 2.9002e-01,\n",
       "        3.0002e-01, 3.1002e-01, 3.2002e-01, 3.3002e-01, 3.4002e-01, 3.5002e-01,\n",
       "        3.6002e-01, 3.7002e-01, 3.8002e-01, 3.9002e-01, 4.0002e-01, 4.1002e-01,\n",
       "        4.2002e-01, 4.3002e-01, 4.4002e-01, 4.5002e-01, 4.6002e-01, 4.7001e-01,\n",
       "        4.8001e-01, 4.9001e-01, 5.0001e-01, 5.1001e-01, 5.2001e-01, 5.3001e-01,\n",
       "        5.4001e-01, 5.5001e-01, 5.6001e-01, 5.7001e-01, 5.8001e-01, 5.9001e-01,\n",
       "        6.0001e-01, 6.1001e-01, 6.2001e-01, 6.3001e-01, 6.4001e-01, 6.5001e-01,\n",
       "        6.6001e-01, 6.7001e-01, 6.8001e-01, 6.9001e-01, 7.0001e-01, 7.1001e-01,\n",
       "        7.2001e-01, 7.3001e-01, 7.4001e-01, 7.5001e-01, 7.6001e-01, 7.7001e-01,\n",
       "        7.8001e-01, 7.9001e-01, 8.0001e-01, 8.1001e-01, 8.2001e-01, 8.3000e-01,\n",
       "        8.4000e-01, 8.5000e-01, 8.6000e-01, 8.7000e-01, 8.8000e-01, 8.9000e-01,\n",
       "        9.0000e-01, 9.1000e-01, 9.2000e-01, 9.3000e-01, 9.4000e-01, 9.5000e-01,\n",
       "        9.6000e-01, 9.7000e-01, 9.8000e-01, 9.9000e-01, 1.0000e+00]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emnist_certainty_scores.histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec89501-629b-4799-8b76-739de14a29be",
   "metadata": {},
   "source": [
    "A preliminary look at the histogram data shows that there is some concentration towards the upper bounds of the certainty score, but otherwise the values are diffused across 0 to 1. Let's look at the MNIST certainty score histogram in contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6143bacf-df06-40a0-abc6-2079ffffdf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.histogram(\n",
       "hist=tensor([3.0000e+00, 3.0000e+00, 4.0000e+00, 3.0000e+00, 3.0000e+00, 4.0000e+00,\n",
       "        4.0000e+00, 2.0000e+00, 4.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00,\n",
       "        3.0000e+00, 1.0000e+00, 0.0000e+00, 5.0000e+00, 1.0000e+00, 2.0000e+00,\n",
       "        2.0000e+00, 0.0000e+00, 2.0000e+00, 3.0000e+00, 6.0000e+00, 2.0000e+00,\n",
       "        1.0000e+00, 2.0000e+00, 3.0000e+00, 5.0000e+00, 5.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 3.0000e+00, 3.0000e+00, 2.0000e+00, 3.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 2.0000e+00, 3.0000e+00, 4.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 2.0000e+00,\n",
       "        2.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00, 4.0000e+00,\n",
       "        3.0000e+00, 4.0000e+00, 3.0000e+00, 4.0000e+00, 3.0000e+00, 1.0000e+00,\n",
       "        4.0000e+00, 3.0000e+00, 4.0000e+00, 4.0000e+00, 3.0000e+00, 3.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 1.2000e+01, 1.0000e+01, 4.0000e+00, 1.0000e+01,\n",
       "        1.0000e+00, 7.0000e+00, 5.0000e+00, 1.2000e+01, 9.0000e+00, 1.0000e+01,\n",
       "        5.0000e+00, 7.0000e+00, 4.0000e+00, 5.0000e+00, 3.0000e+00, 1.3000e+01,\n",
       "        6.0000e+00, 5.0000e+00, 1.6000e+01, 1.7000e+01, 1.3000e+01, 1.6000e+01,\n",
       "        1.5000e+01, 9.0000e+00, 1.8000e+01, 2.9000e+01, 2.7000e+01, 4.4000e+01,\n",
       "        5.6000e+01, 8.9000e+01, 2.1700e+02, 9.1440e+03]),\n",
       "bin_edges=tensor([0.0047, 0.0147, 0.0246, 0.0346, 0.0445, 0.0545, 0.0644, 0.0744, 0.0844,\n",
       "        0.0943, 0.1043, 0.1142, 0.1242, 0.1341, 0.1441, 0.1540, 0.1640, 0.1739,\n",
       "        0.1839, 0.1938, 0.2038, 0.2137, 0.2237, 0.2336, 0.2436, 0.2535, 0.2635,\n",
       "        0.2735, 0.2834, 0.2934, 0.3033, 0.3133, 0.3232, 0.3332, 0.3431, 0.3531,\n",
       "        0.3630, 0.3730, 0.3829, 0.3929, 0.4028, 0.4128, 0.4227, 0.4327, 0.4426,\n",
       "        0.4526, 0.4626, 0.4725, 0.4825, 0.4924, 0.5024, 0.5123, 0.5223, 0.5322,\n",
       "        0.5422, 0.5521, 0.5621, 0.5720, 0.5820, 0.5919, 0.6019, 0.6118, 0.6218,\n",
       "        0.6318, 0.6417, 0.6517, 0.6616, 0.6716, 0.6815, 0.6915, 0.7014, 0.7114,\n",
       "        0.7213, 0.7313, 0.7412, 0.7512, 0.7611, 0.7711, 0.7810, 0.7910, 0.8009,\n",
       "        0.8109, 0.8209, 0.8308, 0.8408, 0.8507, 0.8607, 0.8706, 0.8806, 0.8905,\n",
       "        0.9005, 0.9104, 0.9204, 0.9303, 0.9403, 0.9502, 0.9602, 0.9701, 0.9801,\n",
       "        0.9900, 1.0000]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(alloutputs['certainty_dist'].data.certainty_score).histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249a25cc-f4b1-49d5-9081-bad71bf5a930",
   "metadata": {},
   "source": [
    "Despite being half the size of the EMNIST data, we find that the MNIST data is substantially clustered within the right-most certainty score bin (>99%). In fact, over 91% of the MNIST data is highly certain, whereas only approximately 22% of the out-of-distribution EMNIST data is similarly (mis)classified with high certainty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42541fdd-2477-455b-ab82-415e27abffe9",
   "metadata": {},
   "source": [
    "Let's look in detail at the EMNIST data which has the highest certainty scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e6ab7c3-a025-46e2-8d0b-3af3e00b7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,counts=emnist_model_data.input_data_labeled[(emnist_certainty_scores>9.9e-01).flatten()].unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25ef029e-369a-4b57-b002-f661bf9a2087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 22 letter is the one that is (mis)classified 714 times with the highest certainty\n"
     ]
    }
   ],
   "source": [
    "print(\"The {} letter is the one that is (mis)classified {} times with the highest certainty\".format(counts.argmax().item(),counts.max().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f9062e-3655-4258-9233-ff9e58cec530",
   "metadata": {},
   "source": [
    "We see that the most confidently assigned out-of-distribution letter is 'v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "126760b3-3599-4705-b33d-6e06af45571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llabels,lcounts=emnist_model_data.input_data_labeled[(emnist_certainty_scores<1e-02).flatten()].unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98a7969b-a541-4e41-911a-5772b9f7ed5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 12 letter is the one that is (mis)classified 11 times with the lowest certainty\n"
     ]
    }
   ],
   "source": [
    "print(\"The {} letter is the one that is (mis)classified {} times with the lowest certainty\".format(lcounts.argmax().item(),lcounts.max().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1216d9-0f0e-4191-868c-317e9f94ffdc",
   "metadata": {},
   "source": [
    "On the otherhand, the letter 'l' is (mis)classified with certainty below 0.01 most frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4049445-fa34-40ca-95da-cf3debf9862c",
   "metadata": {},
   "source": [
    "Now let's proceed to first us the above model_uq's associated internal tests. In order to do this, we'll need to form the 'external_data', in this case, the Certainties for the emnist_model_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c436d5aa-365a-4562-a55a-98e321a21338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now gathering certainties\n",
      "Original certainty shape is torch.Size([20800, 10, 10]) from predictions shape torch.Size([20800, 10])\n",
      "Finished gathering certainties.\n"
     ]
    }
   ],
   "source": [
    "emnist_certainties = CandC.model_uq.data.Certainties()\n",
    "emnist_certainties.gather_certainties(output_data=emnist_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "837d2c33-c4e6-414a-847d-d92b822000c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in the external data\n",
      "Starting Omicron tests\n",
      "There are 30800 total items.\n",
      " There are 10000 in-distribution items.\n",
      " There are 20800 out-of-distribution/FP items\n",
      "The accuracy of the log omicron model after fitting is 0.7636038961038961\n",
      "INTERNAL OMICRON TEST\n",
      "----------------------------\n",
      "The scores for the omicron test are tensor([0.0034, 0.0034, 0.0034,  ..., 0.9483, 0.9505, 0.9533])\n",
      " The labels are tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "The tpr tensor is tensor([0.0000e+00, 4.7858e-05, 9.5717e-05,  ..., 9.9990e-01, 9.9995e-01,\n",
      "        1.0000e+00])\n",
      "INTERNAL ONLY: With cut-off at 0.95, \n",
      " fpr tensor([0., 0., 0.,  ..., 1., 1., 1.]) \n",
      " tpr tensor([0.0000e+00, 4.7858e-05, 9.5717e-05,  ..., 9.9990e-01, 9.9995e-01,\n",
      "        1.0000e+00]), the corresponding idx is 24820, \n",
      "with fpr95tpr 1.0\n",
      "Omicron Test Results \n",
      "{'AUROC': tensor(0.8150), 'AUPR-IN': tensor(0.9214), 'AUPR-OUT': tensor(0.5276), 'FPR95TPR': tensor(1.)}\n",
      "EXTERNAL OMICRON TEST\n",
      "----------------------------\n",
      "The scores for the omicron test are tensor([0.4318, 0.4318, 0.4318,  ..., 1.0000, 1.0000, 1.0000])\n",
      " The labels are tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "The tpr tensor is tensor([0.0000e+00, 4.8077e-05, 9.6154e-05,  ..., 9.9904e-01, 9.9952e-01,\n",
      "        1.0000e+00])\n",
      "INTERNAL ONLY: With cut-off at 0.95, \n",
      " fpr tensor([0., 0., 0.,  ..., 1., 1., 1.]) \n",
      " tpr tensor([0.0000e+00, 4.8077e-05, 9.6154e-05,  ..., 9.9904e-01, 9.9952e-01,\n",
      "        1.0000e+00]), the corresponding idx is 25437, \n",
      "with fpr95tpr 1.0\n",
      "Omicron Test Results \n",
      "{'AUROC': tensor(0.7999), 'AUPR-IN': tensor(0.9127), 'AUPR-OUT': tensor(0.5050), 'FPR95TPR': tensor(1.)}\n",
      "Model saved at /home/jovyan/CandC_Framework/tutorial/model_uq\n"
     ]
    }
   ],
   "source": [
    "oodd_params=dict({'external_data_name':'emnist_data',\n",
    "                 'internal_certainties':alloutputs['certainties'],\n",
    "                 'internal_omicrons':alloutputs['omicrons'],\n",
    "                 'external_data':emnist_certainties,\n",
    "                 'scores':alloutputs['scores']})\n",
    "\n",
    "model_uq.run_oodd_tests_internal(**oodd_params)\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1469eb-1915-4ad6-a0c7-ef0722567436",
   "metadata": {},
   "source": [
    "We see that running the 'internal' OODD tests produces results for two types of Omicron test models. The first uses the internal omicron test that is calibrated to distinguish TP from FP values, whereas the second test, the External test, is calibrated to distinguish in-distribution (MNIST) data from out-of-distribution, or novel sample data (here labeled from the EMNIST dataset). Importantly, the accuracy of the log omicron model that is reported above describes the External model's accuracy.  To examine the accuracy of the Internal model, let's run the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63fc04-87a7-43ee-a377-3af0e733c1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4355794f-4d72-47f0-b6c8-e941c7a7bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(),'tutorial','model_uq','emnist_data_oodd_test_results'),'rb') as handle:\n",
    "    oodd_test_results = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "130b542a-2aa0-4765-89a7-a17367b69c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_omicron_internal_test_scores=oodd_test_results['Omicron Test Results']['internal test scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a10920-2d48-4f6b-93c7-e15911d68e44",
   "metadata": {},
   "source": [
    "As the omicron test is an oodd test, FP and OOD labels are valued at 1 and in-distribution or TPs are labeled as 0 when training the logistic model. Further, the outputs are determined straightforwardly by projecting down the output probability vector onto the first probability component. For this reason, we can, if we use a .5 threshold, identify the accuracy of the internal model by the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84b8cacb-66c3-44bb-8b94-c7b1270289a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90064936876297"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emnist_omicron_internal_test_scores<.5).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060d5a2-4b4e-4eb1-8e9f-1e00ddeac616",
   "metadata": {},
   "source": [
    "That is, with respect to the EMNIST data, a little over 90% of the EMNIST data using the Internal Omicron test, can be identified relative to the in-predicted category, in-distribution TP MNIST data, as being a FP. This is determined exactly as 90.06% of the EMNIST sample is seen to have a pseudo-probability for the 'TP' label under 50%, whence the pseudo-probability for FP is at least 50%. Let's look at the external model in contrast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e69dc740-ffcb-45f8-8510-a4914bad915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 0.2358173131942749 of the out-of-distribution data was identified\n",
      " Only 0.7623999714851379 of the in-distribution data was identified\n"
     ]
    }
   ],
   "source": [
    "print(\"Only {} of the out-of-distribution data was identified\\n Only {} of the in-distribution data was identified\".format((oodd_test_results['Omicron Test Results']['external test scores'][:-10000]<.5).float().mean().item(),\n",
    "      (oodd_test_results['Omicron Test Results']['external test scores'][-10000:]<.5).float().mean().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058246e-7b77-42c6-9a19-0bc6f6403665",
   "metadata": {},
   "source": [
    "In contrast with the Internal Test, we find that the external test does rather poorly with the default .5 cutoff.\n",
    "\n",
    "The intuitive reason for this is that we find the EMNIST data is similar enough to the omicrons of the FPs relative to the omicrons of the TPs. When we collapse the entire MNIST sample to the 0 label, the inclusion of the FP certainties in the sample we use when computing the omicrons brings the out of distribution data 'closer' on average to the MNIST data.\n",
    "\n",
    "For this reason, we should generally prefer to use the Internal Omicron Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55427708-86e7-4e66-b19c-b167f89db2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
